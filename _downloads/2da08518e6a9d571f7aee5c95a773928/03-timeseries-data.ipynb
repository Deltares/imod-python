{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\n# Time series data and Pandas\n\nHandling time series is major part of geohydrology and groundwater modeling.\nTime series data come in more than one form:\n\n* Time series linked to a point location, for example a measured groundwater\n  level at a specific location.\n* Time series of a spatially continuous nature, for example model output of\n  calculated head for a specific model layer.\n\nWe typically represent time series data at points as a\n:py:class:`pandas.DataFrame`, despite the (apparent) match with GeoDataFrames.\nThe issue is that a GeoDataFrame has to store the geometry for every row: this\nmeans many duplicated geometries. Fortunately, pandas' `group by`_\n(split-apply-combine) functionality provides a (fairly) convenient way of\nworking with time series data of many points.\n\nPandas provides many tools for working with time series data, such as:\n\n* Input and output to many tabular formats, such as CSV or Excel;\n* Data selection;\n* Filling or interpolating missing data;\n* Resampling to specific frequencies;\n* Plotting.\n\n## Timeseries at point locations\n\niMOD represents time series at points in an IPF format. This format stores\nits data as:\n\n* A \"mother\" file containing the x and y coordinates of the point. Each\n  point can be associated with a timeseries with a label.\n* A timeries file for every point.\n\nThese files can be read via :func:`imod.formats.ipf.read`. The ``read`` function\nwill read the mother file, and follow its labels, reading every associated\ntimeseries file as well. Finally, these are merged into a single large table;\nthe properties of the point (e.g. the x,y coordinates) are duplicated for every\nrow.\n\n<div class=\"alert alert-info\"><h4>Note</h4><p>This may seem wasteful, but:\n\n    * There are few data structures available for storing point data with\n      associated time series. For example: xarray can store the point location\n      as coordinates, but every point will need to share its time axis -- the\n      same time window for every point and the same time resolution.\n    * There are equally few file formats suitable for this data. A single large\n      table is supported by many file formats.\n    * Pandas `group by`_ functionality is quite fast.</p></div>\n\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Example: Head observations\n\nLet's load some example data. We'll load some head observations. This is a\nlarge dataset, originally stored in the IPF format. This dataset has a similar\nform to what :func:`imod.formats.ipf.read` would return.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "import imod\n\nheads = imod.data.head_observations()\nheads"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "We can see that the data is stored in a long format, with duplicate entries\nfor each time. Let's do some selections to showcase some functionality of\npandas. Let's first compute filter depth, which is the difference between the\nsurface_elevation and the top of the filter. Note: \"Meetpunt tov m NAP\" =\nsurface elevation, \"filt_top\" = top of the filter.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "filter_depth = heads[\"Meetpunt tov m NAP\"] - heads[\"filt_top\"]\nfilter_depth"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "The original dataset is very large, so let's limit ourselves to only head\nobservations close to surface elevation. Let's say the first 20 cm below surface.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "heads_shallow = heads.loc[filter_depth < 0.2]\nheads_shallow = heads_shallow.sort_values(by=\"time\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Let's plot the head observations for these shallow observations over time with\na separate line for each filter.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n\nfig, ax = plt.subplots()\nfor key, group in heads_shallow.groupby(\"id\"):\n    ax = group.plot(x=\"time\", y=\"head\", ax=ax, label=key)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "It seems one line disappeared. Let's count the number of observations per\nfilter. We can see that one of the filters has only one observation, making it\nhard to draw a line.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "heads_shallow.groupby(\"id\")[\"head\"].count()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Let's check whether these head observations were all measured at the same\ndate. We can groupby time and count the number of observations per time.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "n_obs_per_time = heads_shallow.groupby(\"time\")[\"id\"].count()\nn_obs_per_time"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "We can see in the printed summary that most dates have only one observation,\nand that the last two dates are only two days apart. This is likely caused by\nobservations on inconsistent dates.\n\nLet's see if there are some dates with more than one observation.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "n_obs_per_time.unique()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "We can see that there are some dates with two observations. Lets's\nsee which dates those are:\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "n_obs_per_time.loc[n_obs_per_time == 2]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## MODFLOW 6\n\niMOD Python's :class:`imod.mf6.Well` and :class:`imod.mf6.LayeredWell` classes\nrequire their data to be provided as points. However, these require the rates\nto be provided on consistent timesteps amongst all points. This means that the\ndata has to be resampled to a consistent frequency. This is done for the user\nwhen calling :meth:`imod.mf6.Well.from_imod5_data` or\n:meth:`imod.mf6.LayeredWell.from_imod5_data`.\n\n"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.12"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}